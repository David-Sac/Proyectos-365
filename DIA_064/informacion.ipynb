{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DIA 064: Creación de un Web Scraper Avanzado con Selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hoy aprenderemos a realizar web scraping avanzado con Selenium para automatizar la extracción de datos de sitios web dinámicos.\n",
    "\n",
    "✅ ¿Qué aprenderemos?\n",
    "\n",
    "📌 Usar Selenium WebDriver para interactuar con páginas web.\n",
    "📌 Extraer datos de sitios dinámicos con JavaScript.\n",
    "📌 Guardar la información en un archivo CSV.\n",
    "✅ Ejemplo práctico:\n",
    "Scrapearemos los títulos y precios de productos en una tienda en línea.\n",
    "\n",
    "🛠️ 1. Instalación de Paquetes Necesarios\n",
    "Ejecutar en la terminal:\n",
    "\n",
    "sh\n",
    "Copiar\n",
    "Editar\n",
    "pip install selenium pandas\n",
    "📌 Descargar WebDriver:\n",
    "Para usar Selenium, necesitas un WebDriver compatible con tu navegador.\n",
    "\n",
    "Chrome: Descargar ChromeDriver\n",
    "Firefox: Descargar GeckoDriver\n",
    "📌 Coloca el WebDriver en la misma carpeta del script o configura el PATH.\n",
    "\n",
    "🖥️ 2. Código Completo (scraper_selenium.py)\n",
    "python\n",
    "Copiar\n",
    "Editar\n",
    "import time\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "# ---------------------------\n",
    "# 1. Configurar Selenium\n",
    "# ---------------------------\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"--headless\")  # Ejecutar en segundo plano\n",
    "options.add_argument(\"--no-sandbox\")\n",
    "options.add_argument(\"--disable-dev-shm-usage\")\n",
    "\n",
    "# Iniciar WebDriver\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "\n",
    "# ---------------------------\n",
    "# 2. Acceder a la Página Web\n",
    "# ---------------------------\n",
    "URL = \"https://webscraper.io/test-sites/e-commerce/allinone/computers/laptops\"\n",
    "driver.get(URL)\n",
    "time.sleep(3)  # Esperar a que cargue la página\n",
    "\n",
    "# ---------------------------\n",
    "# 3. Extraer Datos de la Página\n",
    "# ---------------------------\n",
    "productos = driver.find_elements(By.CLASS_NAME, \"thumbnail\")\n",
    "\n",
    "data = []\n",
    "for producto in productos:\n",
    "    titulo = producto.find_element(By.CLASS_NAME, \"title\").text\n",
    "    precio = producto.find_element(By.CLASS_NAME, \"price\").text\n",
    "    data.append({\"Título\": titulo, \"Precio\": precio})\n",
    "\n",
    "# ---------------------------\n",
    "# 4. Guardar Datos en un CSV\n",
    "# ---------------------------\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv(\"productos.csv\", index=False)\n",
    "\n",
    "print(\"✅ Datos guardados en productos.csv\")\n",
    "\n",
    "# ---------------------------\n",
    "# 5. Cerrar el Navegador\n",
    "# ---------------------------\n",
    "driver.quit()\n",
    "🚀 Cómo Ejecutar el Web Scraper\n",
    "Ejecutar en la terminal:\n",
    "\n",
    "sh\n",
    "Copiar\n",
    "Editar\n",
    "python scraper_selenium.py\n",
    "📌 Salida esperada:\n",
    "✅ Datos guardados en productos.csv\n",
    "\n",
    "📜 Ejemplo de contenido del CSV:\n",
    "\n",
    "csv\n",
    "Copiar\n",
    "Editar\n",
    "Título,Precio\n",
    "\"Laptop HP 15\",\"$499.99\"\n",
    "\"Dell XPS 13\",\"$899.99\"\n",
    "...\n",
    "🔍 Explicación de las Principales Implementaciones\n",
    "🔹 📂 Uso de webdriver.Chrome() con opciones avanzadas\n",
    "\n",
    "options.add_argument(\"--headless\") ejecuta Selenium sin abrir el navegador.\n",
    "🔹 🌍 Navegación y Esperas\n",
    "\n",
    "driver.get(URL) abre la página web.\n",
    "time.sleep(3) espera 3 segundos para que cargue el contenido.\n",
    "🔹 📜 Extraer Datos con find_elements()\n",
    "\n",
    "By.CLASS_NAME, \"title\" obtiene el título del producto.\n",
    "By.CLASS_NAME, \"price\" extrae el precio.\n",
    "🔹 💾 Guardado de Datos en CSV\n",
    "\n",
    "df.to_csv(\"productos.csv\", index=False) almacena la información en un archivo.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
