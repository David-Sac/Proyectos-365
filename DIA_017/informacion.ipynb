{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DIA 017: Optimización Avanzada del Fine-Tuning y Monitorización Mejorada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimizar el Fine-Tuning Avanzado del Modelo:\n",
    "\n",
    "Descongelar Más Capas del Modelo Base (VGG16): Permitir que más capas aprendan características específicas del dataset MNIST.\n",
    "Aplicar Técnicas de Regularización Adicionales: Como Batch Normalization para estabilizar y acelerar el entrenamiento.\n",
    "Implementar un Scheduler de Tasa de Aprendizaje: Ajustar dinámicamente la tasa de aprendizaje durante el entrenamiento para mejorar la convergencia.\n",
    "Mejorar la Monitorización del Entrenamiento:\n",
    "\n",
    "Integrar TensorBoard: Para visualizar métricas de entrenamiento en tiempo real.\n",
    "Guardar Modelos en Diferentes Puntos: Además del mejor modelo, guardar checkpoints a intervalos regulares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Importación de Librerías\n",
    "# ------------------------------------\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, TensorBoard\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import datetime  # Para timestamp en TensorBoard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Cargar el Modelo Final Entrenado\n",
    "# ------------------------------------\n",
    "\n",
    "# Cargar el modelo completamente entrenado del Día 16\n",
    "modelo_final = tf.keras.models.load_model('modelo_cnn_transfer_learning_mnist_final.h5')\n",
    "print(\"Modelo final cargado exitosamente.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Descongelar Más Capas para Fine-Tuning Avanzado\n",
    "# ------------------------------------\n",
    "\n",
    "# Obtener la capa base del modelo (VGG16)\n",
    "base_model = modelo_final.layers[0]\n",
    "\n",
    "# Mostrar las capas actuales y su estado de entrenabilidad\n",
    "print(\"Capas antes de descongelar:\")\n",
    "for i, layer in enumerate(base_model.layers):\n",
    "    print(f\"{i}: {layer.name} - {'Entrenable' if layer.trainable else 'Congelada'}\")\n",
    "\n",
    "# Descongelar todas las capas a partir de 'block4_conv1'\n",
    "set_trainable = False\n",
    "for layer in base_model.layers:\n",
    "    if layer.name == 'block4_conv1':\n",
    "        set_trainable = True\n",
    "    if set_trainable:\n",
    "        layer.trainable = True\n",
    "    else:\n",
    "        layer.trainable = False\n",
    "\n",
    "# Verificar el estado de las capas después de descongelar\n",
    "print(\"\\nCapas después de descongelar:\")\n",
    "for i, layer in enumerate(base_model.layers):\n",
    "    print(f\"{i}: {layer.name} - {'Entrenable' if layer.trainable else 'Congelada'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Añadir Capas de Regularización Adicionales\n",
    "# ------------------------------------\n",
    "\n",
    "# Reconstruir el modelo con Batch Normalization\n",
    "modelo_optimizado = models.Sequential([\n",
    "    base_model,\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.BatchNormalization(),  # Añadir Batch Normalization\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(10, activation='softmax')  # 10 clases para MNIST\n",
    "])\n",
    "\n",
    "# Resumen del modelo optimizado\n",
    "modelo_optimizado.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Recompilar el Modelo con un Scheduler de Tasa de Aprendizaje\n",
    "# ------------------------------------\n",
    "\n",
    "# Recompilar el modelo optimizado con una tasa de aprendizaje más baja\n",
    "modelo_optimizado.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
    "                          loss='sparse_categorical_crossentropy',\n",
    "                          metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Configurar TensorBoard para Monitorización Mejorada\n",
    "# ------------------------------------\n",
    "\n",
    "# Crear un timestamp para los logs de TensorBoard\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "# Definir callbacks adicionales\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "                              patience=2, min_lr=1e-7, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Reentrenar el Modelo con Fine-Tuning Optimizado\n",
    "# ------------------------------------\n",
    "\n",
    "# Definir callbacks para el entrenamiento\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True),\n",
    "    ModelCheckpoint('mejor_modelo_ft.h5', monitor='val_loss', save_best_only=True, verbose=1),\n",
    "    reduce_lr,\n",
    "    tensorboard_callback\n",
    "]\n",
    "\n",
    "# Reentrenar el modelo optimizado con fine-tuning avanzado\n",
    "history_ft = modelo_optimizado.fit(\n",
    "    train_ds,\n",
    "    epochs=10,  # Puedes ajustar el número de épocas según sea necesario\n",
    "    validation_data=val_ds,\n",
    "    callbacks=callbacks\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Evaluar y Visualizar el Rendimiento Mejorado\n",
    "# ------------------------------------\n",
    "\n",
    "# Evaluar el modelo después del fine-tuning optimizado\n",
    "test_loss_ft, test_acc_ft = modelo_optimizado.evaluate(val_ds, verbose=2)\n",
    "print(f'\\nPrecisión en el conjunto de prueba después del fine-tuning optimizado: {test_acc_ft:.4f}')\n",
    "\n",
    "# Graficar precisión y pérdida durante el fine-tuning optimizado\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# Precisión\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history_ft.history['accuracy'], label='Entrenamiento')\n",
    "plt.plot(history_ft.history['val_accuracy'], label='Validación')\n",
    "plt.title('Precisión durante el Fine-Tuning Optimizado')\n",
    "plt.xlabel('Época')\n",
    "plt.ylabel('Precisión')\n",
    "plt.legend()\n",
    "\n",
    "# Pérdida\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history_ft.history['loss'], label='Entrenamiento')\n",
    "plt.plot(history_ft.history['val_loss'], label='Validación')\n",
    "plt.title('Pérdida durante el Fine-Tuning Optimizado')\n",
    "plt.xlabel('Época')\n",
    "plt.ylabel('Pérdida')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. Guardar el Modelo Final Optimizado\n",
    "# ------------------------------------\n",
    "\n",
    "# Guardar el modelo completamente optimizado\n",
    "modelo_optimizado.save('modelo_cnn_transfer_learning_mnist_final_optimizado.h5')\n",
    "print(\"Modelo final optimizado guardado como 'modelo_cnn_transfer_learning_mnist_final_optimizado.h5'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. Hacer Predicciones con el Modelo Final Optimizado\n",
    "# ------------------------------------\n",
    "\n",
    "# Hacer predicciones sobre el conjunto de prueba con el modelo optimizado\n",
    "predicciones_ft = modelo_optimizado.predict(val_ds)\n",
    "clases_predichas_ft = np.argmax(predicciones_ft, axis=1)\n",
    "\n",
    "# Mostrar predicción para la primera imagen del conjunto de prueba\n",
    "indice = 0\n",
    "print(f\"Etiqueta real: {y_test[indice]}\")\n",
    "print(f\"Predicción: {clases_predichas_ft[indice]}\")\n",
    "print(f\"Probabilidades: {predicciones_ft[indice]}\")\n",
    "\n",
    "# Visualizar la imagen con su predicción\n",
    "def mostrar_prediccion(matriz, etiquetas, predicciones, indice):\n",
    "    plt.figure(figsize=(2,2))\n",
    "    plt.imshow(matriz[indice].reshape(28, 28), cmap='gray')\n",
    "    plt.title(f\"Real: {etiquetas[indice]}\\nPred: {predicciones[indice]}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Mostrar la primera imagen del conjunto de prueba con su predicción\n",
    "mostrar_prediccion(X_test, y_test, clases_predichas_ft, indice)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11. Evaluación Más Detallada (Reporte de Clasificación y Matriz de Confusión)\n",
    "# ------------------------------------\n",
    "\n",
    "# Imprimir el reporte de clasificación\n",
    "print(\"Reporte de Clasificación después del Fine-Tuning Optimizado:\\n\")\n",
    "print(classification_report(y_test, clases_predichas_ft))\n",
    "\n",
    "# Generar la matriz de confusión\n",
    "cm_ft = confusion_matrix(y_test, clases_predichas_ft)\n",
    "\n",
    "# Visualizar la matriz de confusión\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(cm_ft, annot=True, fmt='d', cmap='Greens', \n",
    "            xticklabels=np.unique(y_train), \n",
    "            yticklabels=np.unique(y_train))\n",
    "plt.xlabel('Predicción')\n",
    "plt.ylabel('Realidad')\n",
    "plt.title('Matriz de Confusión después del Fine-Tuning Optimizado')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
