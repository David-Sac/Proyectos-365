{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DIA 060: ImplementaciÃ³n de Web Scraping con Python y BeautifulSoup\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hoy aprenderemos a extraer informaciÃ³n de pÃ¡ginas web usando BeautifulSoup y requests en Python.\n",
    "\n",
    "âœ… Â¿QuÃ© aprenderemos?\n",
    "\n",
    "ğŸ“Œ Obtener el cÃ³digo HTML de una web.\n",
    "ğŸ“Œ Extraer datos especÃ­ficos (tÃ­tulos, enlaces, imÃ¡genes).\n",
    "ğŸ“Œ Almacenar los datos en un archivo CSV.\n",
    "âœ… Ejemplo prÃ¡ctico:\n",
    "Extraeremos los tÃ­tulos y enlaces de noticias de una pÃ¡gina web.\n",
    "\n",
    "ğŸ› ï¸ 1. InstalaciÃ³n de Paquetes Necesarios\n",
    "Ejecutar en la terminal:\n",
    "\n",
    "sh\n",
    "Copiar\n",
    "Editar\n",
    "pip install requests beautifulsoup4 pandas\n",
    "ğŸ–¥ï¸ 2. CÃ³digo Completo (scraper.py)\n",
    "python\n",
    "Copiar\n",
    "Editar\n",
    "import requests\n",
    "import csv\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# ---------------------------\n",
    "# 1. Obtener el HTML de la PÃ¡gina\n",
    "# ---------------------------\n",
    "URL = \"https://news.ycombinator.com/\"  # PÃ¡gina de noticias de tecnologÃ­a\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "response = requests.get(URL, headers=headers)\n",
    "\n",
    "# Validar si la solicitud fue exitosa\n",
    "if response.status_code == 200:\n",
    "    print(\"âœ… ConexiÃ³n exitosa\")\n",
    "else:\n",
    "    print(f\"âŒ Error {response.status_code}\")\n",
    "    exit()\n",
    "\n",
    "# ---------------------------\n",
    "# 2. Parsear el HTML con BeautifulSoup\n",
    "# ---------------------------\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "# ---------------------------\n",
    "# 3. Extraer Titulares y Enlaces\n",
    "# ---------------------------\n",
    "news_data = []\n",
    "news_items = soup.find_all(\"a\", class_=\"storylink\")  # Extraer noticias\n",
    "\n",
    "for item in news_items:\n",
    "    title = item.text\n",
    "    link = item[\"href\"]\n",
    "    news_data.append({\"TÃ­tulo\": title, \"Enlace\": link})\n",
    "\n",
    "# ---------------------------\n",
    "# 4. Guardar los Datos en un Archivo CSV\n",
    "# ---------------------------\n",
    "csv_filename = \"noticias.csv\"\n",
    "\n",
    "with open(csv_filename, \"w\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
    "    fieldnames = [\"TÃ­tulo\", \"Enlace\"]\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(news_data)\n",
    "\n",
    "print(f\"ğŸ“ Datos guardados en {csv_filename}\")\n",
    "\n",
    "# ---------------------------\n",
    "# 5. Mostrar Datos en Pandas\n",
    "# ---------------------------\n",
    "df = pd.DataFrame(news_data)\n",
    "print(df.head())\n",
    "ğŸš€ CÃ³mo Ejecutar el Script\n",
    "Ejecutar en la terminal:\n",
    "\n",
    "sh\n",
    "Copiar\n",
    "Editar\n",
    "python scraper.py\n",
    "ğŸ“Œ Salida esperada:\n",
    "âœ… ConexiÃ³n exitosa\n",
    "ğŸ“ Datos guardados en noticias.csv\n",
    "\n",
    "ğŸ“œ Ejemplo de contenido del CSV:\n",
    "\n",
    "csv\n",
    "Copiar\n",
    "Editar\n",
    "TÃ­tulo,Enlace\n",
    "\"Tech News 1\",\"https://example.com/news1\"\n",
    "\"Tech News 2\",\"https://example.com/news2\"\n",
    "...\n",
    "ğŸ” ExplicaciÃ³n de las Principales Implementaciones\n",
    "ğŸ”¹ ğŸ“‚ Uso de requests para Obtener HTML\n",
    "\n",
    "requests.get(URL, headers=headers) obtiene el cÃ³digo fuente.\n",
    "Se valida si la respuesta es 200 OK.\n",
    "ğŸ”¹ ğŸ“œ Parseo de HTML con BeautifulSoup\n",
    "\n",
    "soup.find_all(\"a\", class_=\"storylink\") encuentra los titulares.\n",
    "item.text obtiene el tÃ­tulo, item[\"href\"] obtiene el enlace.\n",
    "ğŸ”¹ ğŸ’¾ Guardado de Datos en CSV con csv.DictWriter\n",
    "\n",
    "writer.writeheader() escribe los nombres de las columnas.\n",
    "writer.writerows(news_data) guarda todas las noticias.\n",
    "ğŸ”¹ ğŸ“Š VisualizaciÃ³n con Pandas\n",
    "\n",
    "df = pd.DataFrame(news_data) convierte los datos en tabla.\n",
    "df.head() muestra los primeros resultados.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
