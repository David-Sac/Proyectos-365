{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DIA 060: Implementación de Web Scraping con Python y BeautifulSoup\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hoy aprenderemos a extraer información de páginas web usando BeautifulSoup y requests en Python.\n",
    "\n",
    "✅ ¿Qué aprenderemos?\n",
    "\n",
    "📌 Obtener el código HTML de una web.\n",
    "📌 Extraer datos específicos (títulos, enlaces, imágenes).\n",
    "📌 Almacenar los datos en un archivo CSV.\n",
    "✅ Ejemplo práctico:\n",
    "Extraeremos los títulos y enlaces de noticias de una página web.\n",
    "\n",
    "🛠️ 1. Instalación de Paquetes Necesarios\n",
    "Ejecutar en la terminal:\n",
    "\n",
    "sh\n",
    "Copiar\n",
    "Editar\n",
    "pip install requests beautifulsoup4 pandas\n",
    "🖥️ 2. Código Completo (scraper.py)\n",
    "python\n",
    "Copiar\n",
    "Editar\n",
    "import requests\n",
    "import csv\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# ---------------------------\n",
    "# 1. Obtener el HTML de la Página\n",
    "# ---------------------------\n",
    "URL = \"https://news.ycombinator.com/\"  # Página de noticias de tecnología\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "response = requests.get(URL, headers=headers)\n",
    "\n",
    "# Validar si la solicitud fue exitosa\n",
    "if response.status_code == 200:\n",
    "    print(\"✅ Conexión exitosa\")\n",
    "else:\n",
    "    print(f\"❌ Error {response.status_code}\")\n",
    "    exit()\n",
    "\n",
    "# ---------------------------\n",
    "# 2. Parsear el HTML con BeautifulSoup\n",
    "# ---------------------------\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "# ---------------------------\n",
    "# 3. Extraer Titulares y Enlaces\n",
    "# ---------------------------\n",
    "news_data = []\n",
    "news_items = soup.find_all(\"a\", class_=\"storylink\")  # Extraer noticias\n",
    "\n",
    "for item in news_items:\n",
    "    title = item.text\n",
    "    link = item[\"href\"]\n",
    "    news_data.append({\"Título\": title, \"Enlace\": link})\n",
    "\n",
    "# ---------------------------\n",
    "# 4. Guardar los Datos en un Archivo CSV\n",
    "# ---------------------------\n",
    "csv_filename = \"noticias.csv\"\n",
    "\n",
    "with open(csv_filename, \"w\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
    "    fieldnames = [\"Título\", \"Enlace\"]\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(news_data)\n",
    "\n",
    "print(f\"📁 Datos guardados en {csv_filename}\")\n",
    "\n",
    "# ---------------------------\n",
    "# 5. Mostrar Datos en Pandas\n",
    "# ---------------------------\n",
    "df = pd.DataFrame(news_data)\n",
    "print(df.head())\n",
    "🚀 Cómo Ejecutar el Script\n",
    "Ejecutar en la terminal:\n",
    "\n",
    "sh\n",
    "Copiar\n",
    "Editar\n",
    "python scraper.py\n",
    "📌 Salida esperada:\n",
    "✅ Conexión exitosa\n",
    "📁 Datos guardados en noticias.csv\n",
    "\n",
    "📜 Ejemplo de contenido del CSV:\n",
    "\n",
    "csv\n",
    "Copiar\n",
    "Editar\n",
    "Título,Enlace\n",
    "\"Tech News 1\",\"https://example.com/news1\"\n",
    "\"Tech News 2\",\"https://example.com/news2\"\n",
    "...\n",
    "🔍 Explicación de las Principales Implementaciones\n",
    "🔹 📂 Uso de requests para Obtener HTML\n",
    "\n",
    "requests.get(URL, headers=headers) obtiene el código fuente.\n",
    "Se valida si la respuesta es 200 OK.\n",
    "🔹 📜 Parseo de HTML con BeautifulSoup\n",
    "\n",
    "soup.find_all(\"a\", class_=\"storylink\") encuentra los titulares.\n",
    "item.text obtiene el título, item[\"href\"] obtiene el enlace.\n",
    "🔹 💾 Guardado de Datos en CSV con csv.DictWriter\n",
    "\n",
    "writer.writeheader() escribe los nombres de las columnas.\n",
    "writer.writerows(news_data) guarda todas las noticias.\n",
    "🔹 📊 Visualización con Pandas\n",
    "\n",
    "df = pd.DataFrame(news_data) convierte los datos en tabla.\n",
    "df.head() muestra los primeros resultados.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
