{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DIA 013: Transfer Llearning en CCN con Tensorflow y Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transfer Learning es una técnica en el campo del aprendizaje profundo donde un modelo desarrollado para una tarea se reutiliza como punto de partida para un modelo en una segunda tarea. Esto es especialmente útil cuando se dispone de un conjunto de datos pequeño o cuando se busca acelerar el proceso de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Importación de Librerías\n",
    "# ------------------------------------\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Verificación de la Disponibilidad de GPU\n",
    "# ------------------------------------\n",
    "\n",
    "# Verificar si TensorFlow detecta una GPU\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    print(f\"GPU(s) disponible(s): {[gpu.name for gpu in gpus]}\")\n",
    "else:\n",
    "    print(\"No hay GPU disponible. El entrenamiento se realizará en CPU, lo cual puede ser más lento.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Carga y Preprocesamiento de Datos\n",
    "# ------------------------------------\n",
    "\n",
    "# a. Cargar el dataset MNIST\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# b. Normalizar los valores de píxeles de 0-255 a 0-1\n",
    "X_train = X_train.astype('float32') / 255.0\n",
    "X_test = X_test.astype('float32') / 255.0\n",
    "\n",
    "# c. Añadir la dimensión de los canales (1 para escala de grises)\n",
    "X_train = X_train.reshape((X_train.shape[0], 28, 28, 1))\n",
    "X_test = X_test.reshape((X_test.shape[0], 28, 28, 1))\n",
    "\n",
    "# d. Verificar la forma de los datos\n",
    "print(\"Forma de X_train:\", X_train.shape)  # (60000, 28, 28, 1)\n",
    "print(\"Forma de X_test:\", X_test.shape)    # (10000, 28, 28, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Visualización de Datos (Opcional)\n",
    "# ------------------------------------\n",
    "\n",
    "# Función para visualizar imágenes\n",
    "def mostrar_imagen(matriz, etiqueta, indice):\n",
    "    plt.figure(figsize=(2,2))\n",
    "    plt.imshow(matriz[indice].reshape(28, 28), cmap='gray')\n",
    "    plt.title(f\"Dígito: {etiqueta}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Mostrar la primera imagen del conjunto de entrenamiento\n",
    "mostrar_imagen(X_train, y_train, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Definir la Función de Preprocesamiento\n",
    "# ------------------------------------\n",
    "\n",
    "def preprocesar_imagen(x, y):\n",
    "    \"\"\"\n",
    "    Redimensiona las imágenes a 224x224 y convierte de escala de grises a RGB.\n",
    "    \n",
    "    Args:\n",
    "        x (tf.Tensor): Imagen de entrada con forma (28, 28, 1).\n",
    "        y (tf.Tensor): Etiqueta correspondiente.\n",
    "        \n",
    "    Returns:\n",
    "        tuple: Imagen preprocesada y etiqueta.\n",
    "    \"\"\"\n",
    "    # x tiene forma (28, 28, 1)\n",
    "    \n",
    "    # a. Redimensionar la imagen a 224x224\n",
    "    x = tf.image.resize(x, [224, 224])\n",
    "    \n",
    "    # b. Convertir de escala de grises a RGB (duplicar el canal)\n",
    "    x = tf.image.grayscale_to_rgb(x)\n",
    "    \n",
    "    # c. Normalizar los valores de píxeles a [0, 1]\n",
    "    x = tf.cast(x, tf.float32) / 255.0\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Crear los Objetos tf.data.Dataset\n",
    "# ------------------------------------\n",
    "\n",
    "# a. Crear el dataset de entrenamiento\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "train_ds = train_ds.map(preprocesar_imagen, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "train_ds = train_ds.shuffle(buffer_size=1024).batch(64).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# b. Crear el dataset de validación\n",
    "val_ds = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
    "val_ds = val_ds.map(preprocesar_imagen, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "val_ds = val_ds.batch(64).prefetch(tf.data.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Construcción del Modelo con Transfer Learning\n",
    "# ------------------------------------\n",
    "\n",
    "# a. Cargar el modelo VGG16 sin las capas superiores y con pesos preentrenados en ImageNet\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# b. Congelar las capas del modelo base para que no se actualicen durante el entrenamiento\n",
    "base_model.trainable = False\n",
    "\n",
    "# c. Construir el modelo completo con Transfer Learning\n",
    "model = models.Sequential([\n",
    "    base_model,\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(10, activation='softmax')  # 10 clases para MNIST\n",
    "])\n",
    "\n",
    "# d. Resumen del modelo\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Compilación del Modelo\n",
    "# ------------------------------------\n",
    "\n",
    "# Compilar el modelo definiendo el optimizador, la función de pérdida y las métricas\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. Definir Early Stopping\n",
    "# ------------------------------------\n",
    "\n",
    "# Definir Early Stopping para detener el entrenamiento si la pérdida de validación no mejora\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. Entrenamiento del Modelo\n",
    "# ------------------------------------\n",
    "\n",
    "# Entrenar el modelo usando los datasets de entrenamiento y validación\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    epochs=20,\n",
    "    validation_data=val_ds,\n",
    "    callbacks=[early_stop]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11. Evaluación del Modelo\n",
    "# ------------------------------------\n",
    "\n",
    "# Evaluar el rendimiento en el conjunto de prueba\n",
    "test_loss, test_acc = model.evaluate(val_ds, verbose=2)\n",
    "print(f'\\nPrecisión en el conjunto de prueba: {test_acc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12. Visualización del Rendimiento del Modelo\n",
    "# ------------------------------------\n",
    "\n",
    "# Graficar precisión y pérdida durante el entrenamiento\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# Precisión\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Entrenamiento')\n",
    "plt.plot(history.history['val_accuracy'], label='Validación')\n",
    "plt.title('Precisión durante el Entrenamiento')\n",
    "plt.xlabel('Época')\n",
    "plt.ylabel('Precisión')\n",
    "plt.legend()\n",
    "\n",
    "# Pérdida\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Entrenamiento')\n",
    "plt.plot(history.history['val_loss'], label='Validación')\n",
    "plt.title('Pérdida durante el Entrenamiento')\n",
    "plt.xlabel('Época')\n",
    "plt.ylabel('Pérdida')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13. Guardado y Carga del Modelo\n",
    "# ------------------------------------\n",
    "\n",
    "# a. Guardar el modelo completo en un archivo H5\n",
    "model.save('modelo_cnn_transfer_learning_mnist.h5')\n",
    "print(\"Modelo guardado como 'modelo_cnn_transfer_learning_mnist.h5'\")\n",
    "\n",
    "# b. Cargar el modelo guardado\n",
    "loaded_model = tf.keras.models.load_model('modelo_cnn_transfer_learning_mnist.h5')\n",
    "print(\"Modelo cargado exitosamente.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 14. Hacer Predicciones con el Modelo Cargado\n",
    "# ------------------------------------\n",
    "\n",
    "# a. Hacer predicciones sobre el conjunto de prueba\n",
    "predicciones = loaded_model.predict(val_ds)\n",
    "\n",
    "# b. Obtener las clases predichas\n",
    "clases_predichas = np.argmax(predicciones, axis=1)\n",
    "\n",
    "# c. Mostrar predicción para la primera imagen del conjunto de prueba\n",
    "indice = 0\n",
    "print(f\"Etiqueta real: {y_test[indice]}\")\n",
    "print(f\"Predicción: {clases_predichas[indice]}\")\n",
    "print(f\"Probabilidades: {predicciones[indice]}\")\n",
    "\n",
    "# d. Visualizar la imagen con su predicción\n",
    "def mostrar_prediccion(matriz, etiquetas, predicciones, indice):\n",
    "    plt.figure(figsize=(2,2))\n",
    "    plt.imshow(matriz[indice].reshape(28, 28), cmap='gray')\n",
    "    plt.title(f\"Real: {etiquetas[indice]}\\nPred: {predicciones[indice]}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Mostrar la primera imagen del conjunto de prueba con su predicción\n",
    "mostrar_prediccion(X_test, y_test, clases_predichas, indice)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 15. Evaluación Más Detallada (Opcional)\n",
    "# ------------------------------------\n",
    "\n",
    "# Imprimir el reporte de clasificación\n",
    "print(\"Reporte de Clasificación:\\n\")\n",
    "print(classification_report(y_test, clases_predichas))\n",
    "\n",
    "# Generar la matriz de confusión\n",
    "cm = confusion_matrix(y_test, clases_predichas)\n",
    "\n",
    "# Visualizar la matriz de confusión\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=np.unique(y_train), \n",
    "            yticklabels=np.unique(y_train))\n",
    "plt.xlabel('Predicción')\n",
    "plt.ylabel('Realidad')\n",
    "plt.title('Matriz de Confusión')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
