{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DIA 014: Fine-Turning del Modelo Preentrenado VGG16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Después de entrenar las capas superiores de tu modelo con VGG16 congelado, el siguiente paso es fine-tuning. Esto implica descongelar algunas capas del modelo base (VGG16) y entrenarlas junto con las capas superiores para adaptar mejor las características aprendidas al nuevo conjunto de datos (MNIST)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Importación de Librerías\n",
    "# ------------------------------------\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Verificación de la Disponibilidad de GPU\n",
    "# ------------------------------------\n",
    "\n",
    "# Verificar si TensorFlow detecta una GPU\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    print(f\"GPU(s) disponible(s): {[gpu.name for gpu in gpus]}\")\n",
    "else:\n",
    "    print(\"No hay GPU disponible. El entrenamiento se realizará en CPU, lo cual puede ser más lento.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Carga y Preprocesamiento de Datos\n",
    "# ------------------------------------\n",
    "\n",
    "# a. Cargar el dataset MNIST\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# b. Normalizar los valores de píxeles de 0-255 a 0-1\n",
    "X_train = X_train.astype('float32') / 255.0\n",
    "X_test = X_test.astype('float32') / 255.0\n",
    "\n",
    "# c. Añadir la dimensión de los canales (1 para escala de grises)\n",
    "X_train = X_train.reshape((X_train.shape[0], 28, 28, 1))\n",
    "X_test = X_test.reshape((X_test.shape[0], 28, 28, 1))\n",
    "\n",
    "# d. Verificar la forma de los datos\n",
    "print(\"Forma de X_train:\", X_train.shape)  # (60000, 28, 28, 1)\n",
    "print(\"Forma de X_test:\", X_test.shape)    # (10000, 28, 28, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Visualización de Datos (Opcional)\n",
    "# ------------------------------------\n",
    "\n",
    "# Función para visualizar imágenes\n",
    "def mostrar_imagen(matriz, etiqueta, indice):\n",
    "    plt.figure(figsize=(2,2))\n",
    "    plt.imshow(matriz[indice].reshape(28, 28), cmap='gray')\n",
    "    plt.title(f\"Dígito: {etiqueta}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Mostrar la primera imagen del conjunto de entrenamiento\n",
    "mostrar_imagen(X_train, y_train, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Definir la Función de Preprocesamiento\n",
    "# ------------------------------------\n",
    "\n",
    "def preprocesar_imagen(x, y):\n",
    "    \"\"\"\n",
    "    Redimensiona las imágenes a 224x224 y convierte de escala de grises a RGB.\n",
    "    \n",
    "    Args:\n",
    "        x (tf.Tensor): Imagen de entrada con forma (28, 28, 1).\n",
    "        y (tf.Tensor): Etiqueta correspondiente.\n",
    "        \n",
    "    Returns:\n",
    "        tuple: Imagen preprocesada y etiqueta.\n",
    "    \"\"\"\n",
    "    # x tiene forma (28, 28, 1)\n",
    "    \n",
    "    # a. Redimensionar la imagen a 224x224\n",
    "    x = tf.image.resize(x, [224, 224])\n",
    "    \n",
    "    # b. Convertir de escala de grises a RGB (duplicar el canal)\n",
    "    x = tf.image.grayscale_to_rgb(x)\n",
    "    \n",
    "    # c. Normalizar los valores de píxeles a [0, 1]\n",
    "    x = tf.cast(x, tf.float32) / 255.0\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Crear los Objetos tf.data.Dataset\n",
    "# ------------------------------------\n",
    "\n",
    "# a. Crear el dataset de entrenamiento\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "train_ds = train_ds.map(preprocesar_imagen, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "train_ds = train_ds.shuffle(buffer_size=1024).batch(64).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# b. Crear el dataset de validación\n",
    "val_ds = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
    "val_ds = val_ds.map(preprocesar_imagen, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "val_ds = val_ds.batch(64).prefetch(tf.data.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Construcción del Modelo con Transfer Learning\n",
    "# ------------------------------------\n",
    "\n",
    "# a. Cargar el modelo VGG16 sin las capas superiores y con pesos preentrenados en ImageNet\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# b. Congelar las capas del modelo base para que no se actualicen durante el entrenamiento\n",
    "base_model.trainable = False\n",
    "\n",
    "# c. Construir el modelo completo con Transfer Learning\n",
    "model = models.Sequential([\n",
    "    base_model,\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(10, activation='softmax')  # 10 clases para MNIST\n",
    "])\n",
    "\n",
    "# d. Resumen del modelo\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Compilación del Modelo\n",
    "# ------------------------------------\n",
    "\n",
    "# Compilar el modelo definiendo el optimizador, la función de pérdida y las métricas\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. Definir Early Stopping\n",
    "# ------------------------------------\n",
    "\n",
    "# Definir Early Stopping para detener el entrenamiento si la pérdida de validación no mejora\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. Entrenamiento del Modelo\n",
    "# ------------------------------------\n",
    "\n",
    "# Entrenar el modelo usando los datasets de entrenamiento y validación\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    epochs=20,\n",
    "    validation_data=val_ds,\n",
    "    callbacks=[early_stop]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11. Evaluación del Modelo\n",
    "# ------------------------------------\n",
    "\n",
    "# Evaluar el rendimiento en el conjunto de prueba\n",
    "test_loss, test_acc = model.evaluate(val_ds, verbose=2)\n",
    "print(f'\\nPrecisión en el conjunto de prueba: {test_acc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12. Visualización del Rendimiento del Modelo\n",
    "# ------------------------------------\n",
    "\n",
    "# Graficar precisión y pérdida durante el entrenamiento\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# Precisión\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Entrenamiento')\n",
    "plt.plot(history.history['val_accuracy'], label='Validación')\n",
    "plt.title('Precisión durante el Entrenamiento')\n",
    "plt.xlabel('Época')\n",
    "plt.ylabel('Precisión')\n",
    "plt.legend()\n",
    "\n",
    "# Pérdida\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Entrenamiento')\n",
    "plt.plot(history.history['val_loss'], label='Validación')\n",
    "plt.title('Pérdida durante el Entrenamiento')\n",
    "plt.xlabel('Época')\n",
    "plt.ylabel('Pérdida')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13. Guardado y Carga del Modelo\n",
    "# ------------------------------------\n",
    "\n",
    "# a. Guardar el modelo completo en un archivo H5\n",
    "model.save('modelo_cnn_transfer_learning_mnist.h5')\n",
    "print(\"Modelo guardado como 'modelo_cnn_transfer_learning_mnist.h5'\")\n",
    "\n",
    "# b. Cargar el modelo guardado\n",
    "loaded_model = tf.keras.models.load_model('modelo_cnn_transfer_learning_mnist.h5')\n",
    "print(\"Modelo cargado exitosamente.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 14. Hacer Predicciones con el Modelo Cargado\n",
    "# ------------------------------------\n",
    "\n",
    "# a. Hacer predicciones sobre el conjunto de prueba\n",
    "predicciones = loaded_model.predict(val_ds)\n",
    "\n",
    "# b. Obtener las clases predichas\n",
    "clases_predichas = np.argmax(predicciones, axis=1)\n",
    "\n",
    "# c. Mostrar predicción para la primera imagen del conjunto de prueba\n",
    "indice = 0\n",
    "print(f\"Etiqueta real: {y_test[indice]}\")\n",
    "print(f\"Predicción: {clases_predichas[indice]}\")\n",
    "print(f\"Probabilidades: {predicciones[indice]}\")\n",
    "\n",
    "# d. Visualizar la imagen con su predicción\n",
    "def mostrar_prediccion(matriz, etiquetas, predicciones, indice):\n",
    "    plt.figure(figsize=(2,2))\n",
    "    plt.imshow(matriz[indice].reshape(28, 28), cmap='gray')\n",
    "    plt.title(f\"Real: {etiquetas[indice]}\\nPred: {predicciones[indice]}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Mostrar la primera imagen del conjunto de prueba con su predicción\n",
    "mostrar_prediccion(X_test, y_test, clases_predichas, indice)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 15. Evaluación Más Detallada (Opcional)\n",
    "# ------------------------------------\n",
    "\n",
    "# Imprimir el reporte de clasificación\n",
    "print(\"Reporte de Clasificación:\\n\")\n",
    "print(classification_report(y_test, clases_predichas))\n",
    "\n",
    "# Generar la matriz de confusión\n",
    "cm = confusion_matrix(y_test, clases_predichas)\n",
    "\n",
    "# Visualizar la matriz de confusión\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=np.unique(y_train), \n",
    "            yticklabels=np.unique(y_train))\n",
    "plt.xlabel('Predicción')\n",
    "plt.ylabel('Realidad')\n",
    "plt.title('Matriz de Confusión')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 16. Día 14: Fine-Tuning del Modelo\n",
    "# ------------------------------------\n",
    "\n",
    "# a. Descongelar algunas capas del modelo base para fine-tuning\n",
    "base_model.trainable = True\n",
    "\n",
    "# b. Seleccionar cuántas capas descongelar\n",
    "# Por ejemplo, descongelar las últimas 4 bloques de convolución\n",
    "# VGG16 tiene 5 bloques de convolución\n",
    "for layer in base_model.layers:\n",
    "    if isinstance(layer, layers.Conv2D):\n",
    "        if layer.name.startswith('block5'):\n",
    "            layer.trainable = True\n",
    "        else:\n",
    "            layer.trainable = False\n",
    "\n",
    "# c. Verificar qué capas están entrenables\n",
    "for layer in base_model.layers:\n",
    "    print(f\"{layer.name}: {'Entrenable' if layer.trainable else 'Congelada'}\")\n",
    "\n",
    "# d. Recompilar el modelo con un optimizador de menor tasa de aprendizaje\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# e. Entrenar nuevamente el modelo con fine-tuning\n",
    "history_ft = model.fit(\n",
    "    train_ds,\n",
    "    epochs=10,\n",
    "    validation_data=val_ds,\n",
    "    callbacks=[early_stop]\n",
    ")\n",
    "\n",
    "# f. Evaluar el modelo después del fine-tuning\n",
    "test_loss_ft, test_acc_ft = model.evaluate(val_ds, verbose=2)\n",
    "print(f'\\nPrecisión en el conjunto de prueba después del fine-tuning: {test_acc_ft:.4f}')\n",
    "\n",
    "# g. Visualizar el rendimiento del modelo después del fine-tuning\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# Precisión\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history_ft.history['accuracy'], label='Entrenamiento')\n",
    "plt.plot(history_ft.history['val_accuracy'], label='Validación')\n",
    "plt.title('Precisión durante el Fine-Tuning')\n",
    "plt.xlabel('Época')\n",
    "plt.ylabel('Precisión')\n",
    "plt.legend()\n",
    "\n",
    "# Pérdida\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history_ft.history['loss'], label='Entrenamiento')\n",
    "plt.plot(history_ft.history['val_loss'], label='Validación')\n",
    "plt.title('Pérdida durante el Fine-Tuning')\n",
    "plt.xlabel('Época')\n",
    "plt.ylabel('Pérdida')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# h. Actualizar la matriz de confusión y el reporte de clasificación después del fine-tuning\n",
    "predicciones_ft = model.predict(val_ds)\n",
    "clases_predichas_ft = np.argmax(predicciones_ft, axis=1)\n",
    "\n",
    "print(\"Reporte de Clasificación después del Fine-Tuning:\\n\")\n",
    "print(classification_report(y_test, clases_predichas_ft))\n",
    "\n",
    "# Generar la matriz de confusión\n",
    "cm_ft = confusion_matrix(y_test, clases_predichas_ft)\n",
    "\n",
    "# Visualizar la matriz de confusión\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(cm_ft, annot=True, fmt='d', cmap='Greens', \n",
    "            xticklabels=np.unique(y_train), \n",
    "            yticklabels=np.unique(y_train))\n",
    "plt.xlabel('Predicción')\n",
    "plt.ylabel('Realidad')\n",
    "plt.title('Matriz de Confusión después del Fine-Tuning')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
