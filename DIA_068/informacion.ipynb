{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DIA 068: CreaciÃ³n de un Web Scraper con BeautifulSoup y Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hoy aprenderemos a realizar web scraping con BeautifulSoup para extraer informaciÃ³n estructurada de una pÃ¡gina web y almacenarla en Pandas para su anÃ¡lisis.\n",
    "\n",
    "âœ… Â¿QuÃ© aprenderemos?\n",
    "\n",
    "ğŸ“Œ Usar BeautifulSoup para analizar HTML.\n",
    "ğŸ“Œ Extraer informaciÃ³n estructurada (tÃ­tulos, precios, etc.).\n",
    "ğŸ“Œ Almacenar los datos en Pandas y exportarlos a CSV.\n",
    "âœ… Ejemplo prÃ¡ctico:\n",
    "Extraeremos datos de productos desde un sitio web de ejemplo.\n",
    "\n",
    "ğŸ› ï¸ 1. InstalaciÃ³n de Paquetes Necesarios\n",
    "Ejecutar en la terminal:\n",
    "\n",
    "sh\n",
    "Copiar\n",
    "Editar\n",
    "pip install requests beautifulsoup4 pandas\n",
    "ğŸ“Œ requests permite descargar contenido de pÃ¡ginas web.\n",
    "ğŸ“Œ beautifulsoup4 permite analizar y extraer datos de HTML.\n",
    "ğŸ“Œ pandas se usa para organizar los datos en tablas.\n",
    "\n",
    "ğŸ–¥ï¸ 2. CÃ³digo Completo (scraper_bs4.py)\n",
    "python\n",
    "Copiar\n",
    "Editar\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# ---------------------------\n",
    "# 1. Configurar la URL y descargar contenido\n",
    "# ---------------------------\n",
    "URL = \"https://webscraper.io/test-sites/e-commerce/allinone/computers/laptops\"\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "\n",
    "response = requests.get(URL, headers=headers)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    print(\"âœ… ConexiÃ³n exitosa\")\n",
    "else:\n",
    "    print(\"âŒ Error al acceder a la pÃ¡gina\")\n",
    "\n",
    "# ---------------------------\n",
    "# 2. Analizar el contenido con BeautifulSoup\n",
    "# ---------------------------\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "# ---------------------------\n",
    "# 3. Extraer datos de los productos\n",
    "# ---------------------------\n",
    "productos = soup.find_all(\"div\", class_=\"thumbnail\")\n",
    "\n",
    "data = []\n",
    "for producto in productos:\n",
    "    titulo = producto.find(\"a\", class_=\"title\").text.strip()\n",
    "    precio = producto.find(\"h4\", class_=\"price\").text.strip()\n",
    "    descripcion = producto.find(\"p\", class_=\"description\").text.strip()\n",
    "    \n",
    "    data.append({\"TÃ­tulo\": titulo, \"Precio\": precio, \"DescripciÃ³n\": descripcion})\n",
    "\n",
    "# ---------------------------\n",
    "# 4. Almacenar datos en un DataFrame\n",
    "# ---------------------------\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# ---------------------------\n",
    "# 5. Guardar en un archivo CSV\n",
    "# ---------------------------\n",
    "df.to_csv(\"productos_scraper.csv\", index=False)\n",
    "print(\"âœ… Datos guardados en 'productos_scraper.csv'\")\n",
    "\n",
    "# ---------------------------\n",
    "# 6. Mostrar los primeros registros\n",
    "# ---------------------------\n",
    "print(df.head())\n",
    "ğŸš€ CÃ³mo Ejecutar el Web Scraper\n",
    "Ejecutar en la terminal:\n",
    "\n",
    "sh\n",
    "Copiar\n",
    "Editar\n",
    "python scraper_bs4.py\n",
    "ğŸ“Œ Salida esperada:\n",
    "âœ… ConexiÃ³n exitosa\n",
    "âœ… Datos guardados en productos_scraper.csv\n",
    "\n",
    "ğŸ“œ Ejemplo de contenido del CSV:\n",
    "\n",
    "cs\n",
    "Copiar\n",
    "Editar\n",
    "TÃ­tulo,Precio,DescripciÃ³n\n",
    "\"Laptop HP 15\",\"$499.99\",\"Laptop potente con procesador Intel i5...\"\n",
    "\"Dell XPS 13\",\"$899.99\",\"Ultrabook con pantalla tÃ¡ctil y SSD de 512GB...\"\n",
    "...\n",
    "ğŸ” ExplicaciÃ³n de las Principales Implementaciones\n",
    "ğŸ”¹ ğŸ“‚ Descarga de contenido con requests\n",
    "\n",
    "requests.get(URL, headers=headers) obtiene el HTML de la pÃ¡gina.\n",
    "ğŸ”¹ ğŸŒ Uso de BeautifulSoup para extraer datos\n",
    "\n",
    "soup.find_all(\"div\", class_=\"thumbnail\") obtiene la lista de productos.\n",
    "producto.find(\"a\", class_=\"title\").text.strip() extrae el tÃ­tulo del producto.\n",
    "ğŸ”¹ ğŸ’¾ Almacenar datos en un CSV con Pandas\n",
    "\n",
    "pd.DataFrame(data).to_csv(\"productos_scraper.csv\", index=False) guarda los datos extraÃ­dos."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
