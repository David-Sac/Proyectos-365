{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DIA 068: Creación de un Web Scraper con BeautifulSoup y Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hoy aprenderemos a realizar web scraping con BeautifulSoup para extraer información estructurada de una página web y almacenarla en Pandas para su análisis.\n",
    "\n",
    "✅ ¿Qué aprenderemos?\n",
    "\n",
    "📌 Usar BeautifulSoup para analizar HTML.\n",
    "📌 Extraer información estructurada (títulos, precios, etc.).\n",
    "📌 Almacenar los datos en Pandas y exportarlos a CSV.\n",
    "✅ Ejemplo práctico:\n",
    "Extraeremos datos de productos desde un sitio web de ejemplo.\n",
    "\n",
    "🛠️ 1. Instalación de Paquetes Necesarios\n",
    "Ejecutar en la terminal:\n",
    "\n",
    "sh\n",
    "Copiar\n",
    "Editar\n",
    "pip install requests beautifulsoup4 pandas\n",
    "📌 requests permite descargar contenido de páginas web.\n",
    "📌 beautifulsoup4 permite analizar y extraer datos de HTML.\n",
    "📌 pandas se usa para organizar los datos en tablas.\n",
    "\n",
    "🖥️ 2. Código Completo (scraper_bs4.py)\n",
    "python\n",
    "Copiar\n",
    "Editar\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# ---------------------------\n",
    "# 1. Configurar la URL y descargar contenido\n",
    "# ---------------------------\n",
    "URL = \"https://webscraper.io/test-sites/e-commerce/allinone/computers/laptops\"\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "\n",
    "response = requests.get(URL, headers=headers)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    print(\"✅ Conexión exitosa\")\n",
    "else:\n",
    "    print(\"❌ Error al acceder a la página\")\n",
    "\n",
    "# ---------------------------\n",
    "# 2. Analizar el contenido con BeautifulSoup\n",
    "# ---------------------------\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "# ---------------------------\n",
    "# 3. Extraer datos de los productos\n",
    "# ---------------------------\n",
    "productos = soup.find_all(\"div\", class_=\"thumbnail\")\n",
    "\n",
    "data = []\n",
    "for producto in productos:\n",
    "    titulo = producto.find(\"a\", class_=\"title\").text.strip()\n",
    "    precio = producto.find(\"h4\", class_=\"price\").text.strip()\n",
    "    descripcion = producto.find(\"p\", class_=\"description\").text.strip()\n",
    "    \n",
    "    data.append({\"Título\": titulo, \"Precio\": precio, \"Descripción\": descripcion})\n",
    "\n",
    "# ---------------------------\n",
    "# 4. Almacenar datos en un DataFrame\n",
    "# ---------------------------\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# ---------------------------\n",
    "# 5. Guardar en un archivo CSV\n",
    "# ---------------------------\n",
    "df.to_csv(\"productos_scraper.csv\", index=False)\n",
    "print(\"✅ Datos guardados en 'productos_scraper.csv'\")\n",
    "\n",
    "# ---------------------------\n",
    "# 6. Mostrar los primeros registros\n",
    "# ---------------------------\n",
    "print(df.head())\n",
    "🚀 Cómo Ejecutar el Web Scraper\n",
    "Ejecutar en la terminal:\n",
    "\n",
    "sh\n",
    "Copiar\n",
    "Editar\n",
    "python scraper_bs4.py\n",
    "📌 Salida esperada:\n",
    "✅ Conexión exitosa\n",
    "✅ Datos guardados en productos_scraper.csv\n",
    "\n",
    "📜 Ejemplo de contenido del CSV:\n",
    "\n",
    "cs\n",
    "Copiar\n",
    "Editar\n",
    "Título,Precio,Descripción\n",
    "\"Laptop HP 15\",\"$499.99\",\"Laptop potente con procesador Intel i5...\"\n",
    "\"Dell XPS 13\",\"$899.99\",\"Ultrabook con pantalla táctil y SSD de 512GB...\"\n",
    "...\n",
    "🔍 Explicación de las Principales Implementaciones\n",
    "🔹 📂 Descarga de contenido con requests\n",
    "\n",
    "requests.get(URL, headers=headers) obtiene el HTML de la página.\n",
    "🔹 🌍 Uso de BeautifulSoup para extraer datos\n",
    "\n",
    "soup.find_all(\"div\", class_=\"thumbnail\") obtiene la lista de productos.\n",
    "producto.find(\"a\", class_=\"title\").text.strip() extrae el título del producto.\n",
    "🔹 💾 Almacenar datos en un CSV con Pandas\n",
    "\n",
    "pd.DataFrame(data).to_csv(\"productos_scraper.csv\", index=False) guarda los datos extraídos."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
